{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "splits = ['train', 'valid', 'test']\n",
    "\n",
    "def tape_reader(split):\n",
    "    data = []\n",
    "    p = np.load(f'./data/tape/{split}.npz', allow_pickle=True)\n",
    "    seq_labl = json.load(open(f'./data/{split}.json', 'r'))\n",
    "    # print(len(p), len(seq_labl))\n",
    "    # for i in p:\n",
    "    #     data.append((i))\n",
    "    #     data.append((i, p[i]))\n",
    "    for idx in range(len(seq_labl)):\n",
    "        data.append(\n",
    "            {\n",
    "                'seq': seq_labl[idx][0],\n",
    "                'embed': p[f'{split}-{idx:05d}'],\n",
    "                'labl': seq_labl[idx][1]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return data\n",
    "\n",
    "train = tape_reader('train')\n",
    "valid = tape_reader('valid')\n",
    "test = tape_reader('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8237006664276123 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# print(valid[0]['embed'].item()['avg'])\n",
    "from scipy.stats import stats\n",
    "anchor = valid[0]\n",
    "print(anchor['labl'], type(anchor['labl']))\n",
    "# anchor_embed = anchor['embed'].item()['avg']\n",
    "# print(anchor_embed.size)\n",
    "# anchor_embed = anchor['embed'].item()['pooled']\n",
    "# print(anchor_embed.size)\n",
    "from torch.nn.functional import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_valid=True, use_abs=True, embed_type=pooled, spr=0.06398364741425792\n",
      "use_valid=True, use_abs=True, embed_type=avg, spr=0.28939527949895416\n",
      "use_valid=True, use_abs=False, embed_type=pooled, spr=0.39311592554980107\n",
      "use_valid=True, use_abs=False, embed_type=avg, spr=0.44173396237417134\n",
      "use_valid=False, use_abs=True, embed_type=pooled, spr=0.2376535288304412\n",
      "use_valid=False, use_abs=True, embed_type=avg, spr=0.29011005996109673\n",
      "use_valid=False, use_abs=False, embed_type=pooled, spr=0.3931455325007132\n",
      "use_valid=False, use_abs=False, embed_type=avg, spr=0.4413894754063092\n"
     ]
    }
   ],
   "source": [
    "def predict(train, valid, test, use_valid=False, use_abs=False, embed_type='pooled'):\n",
    "    assert embed_type in ['pooled', 'avg'], 'should choose pooled/avg'\n",
    "    # input data: [{'seq', 'embed', 'labl'}]\n",
    "    anchor = train[0]\n",
    "    anchor_embed = anchor['embed'].item()[embed_type]\n",
    "    anchor_labl = anchor['labl']\n",
    "    # print(anchor_embed.size())\n",
    "\n",
    "    test = test[1:]\n",
    "\n",
    "    if use_valid:\n",
    "        refs = train[1:] + valid[1:]\n",
    "    else:\n",
    "        refs = train[1:]\n",
    "\n",
    "\n",
    "    # ref_embed_labl = []\n",
    "    embed_mat = torch.empty(len(refs), anchor_embed.size)\n",
    "    embed_val = torch.empty(len(refs))\n",
    "\n",
    "    for idx in range(len(refs)):\n",
    "        sample = refs[idx]\n",
    "        # print(embed_mat[idx: idx + 1].shape, type(embed_mat[idx: idx + 1]))\n",
    "        # print(sample['embed'].item()[embed_type].shape, type(sample['embed'].item()[embed_type]))\n",
    "        # print(sample['labl'], type(sample['labl']))\n",
    "        # print(embed_val[idx: idx + 1], type(embed_val[idx: idx + 1]))\n",
    "\n",
    "        if use_abs:\n",
    "            # ref_embed_labl.append((sample['embed'].item()[embed_type], sample['labl']))\n",
    "            # embed_mat[idx: idx + 1] = torch.from_numpy(sample['embed'].item()[embed_type] - anchor_embed.reshape(embed_mat[idx: idx + 1].shape)) # sample['embed'].item()[embed_type]\n",
    "            embed_mat[idx: idx + 1] = torch.from_numpy((sample['embed'].item()[embed_type]).reshape(embed_mat[idx: idx + 1].shape))\n",
    "            embed_val[idx: idx + 1] = sample['labl']\n",
    "        else:\n",
    "            # ref_embed_labl.append((sample['embed'].item()[embed_type] - anchor_embed, sample['labl'] - anchor['labl']))\n",
    "            embed_mat[idx: idx + 1] = torch.from_numpy((sample['embed'].item()[embed_type] - anchor_embed).reshape(embed_mat[idx: idx + 1].shape))\n",
    "            embed_val[idx: idx + 1] = sample['labl'] - anchor_labl\n",
    "\n",
    "\n",
    "    labls = torch.Tensor([e['labl'] for e in test])\n",
    "    embed_mat = normalize(embed_mat, p=2, dim=-1)\n",
    "    # embed_mat = normalize(embed_mat, p=2, dim=-1)\n",
    "    # print(embed_mat.sum(dim=-1).shape)\n",
    "    # print(labls.shape)\n",
    "    # print(embed_mat.shape)\n",
    "\n",
    "    if use_abs:\n",
    "        test_embed = [torch.FloatTensor(e['embed'].item()[embed_type]) for e in test]\n",
    "    else:\n",
    "        test_embed = [torch.FloatTensor(e['embed'].item()[embed_type] - anchor_embed) for e in test]\n",
    "\n",
    "    # print(embed_mat[:2], embed_val[:2], embed_val.shape)\n",
    "    # print(embed_mat.shape, embed_val.shape)\n",
    "    \n",
    "    preds = []\n",
    "    # for idx in tqdm.tqdm(range(len(test))):\n",
    "    for idx in range(len(test)):\n",
    "        dot_sim = torch.matmul(embed_mat, normalize(test_embed[idx], p=2, dim=-1))\n",
    "        # print(torch.softmax(dot_sim, dim=0))\n",
    "        prob = torch.softmax(dot_sim, dim=0)\n",
    "        pred_val = torch.dot(prob, embed_val)\n",
    "        # print(pred_val)\n",
    "        if use_abs:\n",
    "            preds.append(pred_val.item())\n",
    "        else:\n",
    "            preds.append(pred_val.item() + anchor_labl)\n",
    "        # if idx == 20:\n",
    "        #     preds = torch.FloatTensor(preds)\n",
    "        #     print(preds)\n",
    "        #     break\n",
    "        # if idx == 20:\n",
    "        #     break\n",
    "\n",
    "    preds = torch.FloatTensor(preds)\n",
    "    spr = stats.spearmanr(preds.numpy(), labls.numpy())\n",
    "    return preds, labls, spr[0]\n",
    "\n",
    "# use_valid=False, use_abs=False\n",
    "collect = []\n",
    "for v in [True, False]:\n",
    "    for a in [True, False]:\n",
    "        for ebd in ['pooled', 'avg']:\n",
    "            p, l, spr = predict(train, valid, test, use_valid=v, use_abs=a, embed_type=ebd)\n",
    "            collect.append((p, l, spr))\n",
    "            print(f'use_valid={v}, use_abs={a}, embed_type={ebd}, spr={spr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b04a8a131563e1a1950e3cab58cc302104d864a3de359652e1db6ff7e9703b0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
